{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7JjVY7tgYi2Q",
    "outputId": "1c39c0b3-5fd0-4c00-febd-ef5d39cbfc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BIz7UYmw0u9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmbNrceRxA9R"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/Datasets/DaGuan/TextClassification/new_data.7z ./\n",
    "!7z x new_data.7z > /null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlMswXbtowoS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHvEzlC2pEOy"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('new_data/train_set.csv')\n",
    "df_test = pd.read_csv('new_data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "CefZgNGMyRak",
    "outputId": "410fd2d0-ef77-4d09-bcb5-c759dab9693d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b6IHZAIcyeud",
    "outputId": "b3649ef5-bf45-4ca5-87c6-72b988eb13d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204554, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_sRkQZIyjXb"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for document in df['word_seg'].to_list():\n",
    "    sentences.append(document.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdfd3NOIy2Ok"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sentences,\n",
    "                 size=200, \n",
    "                 alpha=0.025, \n",
    "                 window=5, \n",
    "                 min_count=2, \n",
    "                 sample=0.001,\n",
    "                 seed=2019, \n",
    "                 workers=12, \n",
    "                 min_alpha=0.0001,\n",
    "                 sg=0, \n",
    "                 hs=0,\n",
    "                 negative=5, \n",
    "                 ns_exponent=0.75, \n",
    "                 cbow_mean=1,\n",
    "                 iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "4MvUJtBSzudm",
    "outputId": "42b19b82-977d-4dbc-a1a5-ee02a0aefd86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "colab_type": "code",
    "id": "hudCPqioz3Su",
    "outputId": "1a7a41a8-5737-4d7d-8ae8-f2234157a709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.11200121e-02,  6.01657450e-01,  1.19949512e-01,  1.44471455e+00,\n",
       "       -1.96722901e+00, -5.77473819e-01,  3.42355758e-01,  2.17954350e+00,\n",
       "        8.14185143e-01,  1.15457559e+00, -1.00908613e+00,  1.30161107e-01,\n",
       "       -3.43487948e-01,  7.21720934e-01,  7.22807586e-01,  9.73198056e-01,\n",
       "       -1.33312917e+00,  1.66020834e+00,  7.18180835e-01,  1.72288013e+00,\n",
       "        9.36558023e-02, -1.72128290e-01,  7.30379879e-01,  1.56291556e+00,\n",
       "       -3.61094624e-01, -1.22902024e+00, -4.39798594e-01,  9.66652185e-02,\n",
       "       -1.23460698e+00,  1.28045660e-02,  7.29311466e-01,  2.91048624e-02,\n",
       "        1.08619976e+00, -4.14549321e-01,  6.43083572e-01, -1.33042768e-01,\n",
       "       -9.41847086e-01,  4.18553501e-02,  1.13867855e+00, -3.45869005e-01,\n",
       "        1.68908083e+00,  7.86846340e-01, -1.50119352e+00,  1.48496300e-01,\n",
       "       -1.23894715e+00, -5.36717892e-01, -8.91485810e-01, -1.19540855e-01,\n",
       "       -1.06919289e+00,  1.50878143e+00,  1.27489781e+00, -1.59103706e-01,\n",
       "       -3.98129791e-01,  1.63907230e+00, -4.65851396e-01,  2.28960919e+00,\n",
       "        2.56352812e-01,  1.65752790e-04, -1.72283757e+00, -1.06494272e+00,\n",
       "        4.00371701e-01,  8.93828571e-01, -1.13757446e-01, -8.20458472e-01,\n",
       "        3.76833469e-01,  7.26131499e-01,  5.64168870e-01, -5.52936256e-01,\n",
       "       -3.08928347e+00, -2.83123821e-01,  7.25080371e-01,  1.65367532e+00,\n",
       "        4.20510590e-01,  1.46140373e+00, -7.62758195e-01, -3.55943799e-01,\n",
       "       -1.59560883e+00,  8.14987481e-01,  3.05722743e-01,  2.11508498e-01,\n",
       "        4.50780213e-01, -2.53876865e-01,  5.68738759e-01, -9.13708806e-01,\n",
       "        1.97486138e+00, -1.20752883e+00,  2.58786708e-01, -5.81119776e-01,\n",
       "       -4.71764088e-01, -3.44692022e-01,  1.19314933e+00,  8.04469824e-01,\n",
       "        9.59848583e-01,  1.10787320e+00,  5.94364218e-02,  1.09340692e+00,\n",
       "       -1.87886155e+00,  1.12629324e-01, -1.16282247e-01, -2.83388108e-01,\n",
       "        6.15586102e-01, -2.76743382e-01, -3.51264514e-02, -1.14605509e-01,\n",
       "        6.51898086e-01, -1.67717144e-01, -5.76456189e-01, -1.25134736e-01,\n",
       "       -4.59068209e-01,  3.22703123e-01, -1.25553954e+00, -8.43793213e-01,\n",
       "       -4.46022958e-01,  4.12210643e-01,  1.24544716e+00, -9.72079694e-01,\n",
       "       -3.37499410e-01,  1.03613576e-02,  6.79415822e-01, -2.99163699e-01,\n",
       "        6.48037374e-01, -1.17613859e-01, -3.95441264e-01, -7.14567721e-01,\n",
       "       -5.14387377e-02,  2.14334702e+00,  1.26085079e+00, -1.59427309e+00,\n",
       "        4.72291797e-01,  9.82999623e-01, -1.17914128e+00,  2.28086278e-01,\n",
       "        7.80882537e-01, -2.71802336e-01, -1.17953920e+00,  8.35835338e-01,\n",
       "       -7.03112185e-01, -1.12693739e+00,  7.15692222e-01,  1.13477278e+00,\n",
       "       -1.35982656e+00,  4.70576547e-02,  1.24870968e+00,  2.66349912e-01,\n",
       "        1.78351492e-01,  1.64456499e+00,  1.77810211e-02, -2.58888632e-01,\n",
       "        2.19269782e-01,  5.02580814e-02, -3.67817670e-01, -9.30352867e-01,\n",
       "        1.09135747e+00, -3.14862221e-01, -1.87656784e+00, -7.07488596e-01,\n",
       "        8.43690336e-01, -7.78180873e-03, -7.17222095e-01,  5.44336081e-01,\n",
       "        7.95005858e-01,  8.99064004e-01, -2.86057591e-01,  5.33346057e-01,\n",
       "        1.10082912e+00, -2.33055338e-01,  5.30421734e-01,  2.52253830e-01,\n",
       "        2.57375002e+00,  1.31367519e-01,  2.50503629e-01,  3.81368786e-01,\n",
       "        3.66191328e-01,  1.30177176e+00, -9.41562712e-01, -5.19824922e-01,\n",
       "       -3.79478067e-01,  1.18796206e+00, -5.91281652e-01,  4.97659653e-01,\n",
       "        1.55127990e+00,  1.05112958e+00,  4.59804505e-01, -8.98243904e-01,\n",
       "       -5.99071681e-01,  4.91445452e-01, -6.20891869e-01,  1.97007567e-01,\n",
       "       -1.43107787e-01, -5.97160637e-01,  3.51839244e-01, -6.11119628e-01,\n",
       "        1.35389709e+00,  5.62080979e-01,  8.83040488e-01, -2.29145251e-02,\n",
       "        2.91296262e-02, -5.59534073e-01,  3.70927274e-01,  1.50338280e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['816903']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRKaOR5C2yMr"
   },
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnwjwJhq2vxT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shwVlGmo0LmC"
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=50000,\n",
    "    lower=False,\n",
    "    filters=\"\"\n",
    ")\n",
    "tokenizer.fit_on_texts(df['word_seg'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Atio3JGk5PHC"
   },
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxNG9qNN3Wds"
   },
   "outputs": [],
   "source": [
    "train_ = tokenizer.texts_to_sequences(df_train['word_seg'].values)\n",
    "test_ = tokenizer.texts_to_sequences(df_test['word_seg'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IGtndGtH4vXZ",
    "outputId": "a53683d8-04c7-4efd-e4a6-9e0baf75a3f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1822.199999999997"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(list(map(lambda x: len(x), train_)), 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFvALHzF4cL-"
   },
   "outputs": [],
   "source": [
    "train_ = tf.keras.preprocessing.sequence.pad_sequences(train_, maxlen=1800, padding='pre', truncating='pre', value=0.0)\n",
    "test_ = tf.keras.preprocessing.sequence.pad_sequences(test_, maxlen=1800, padding='pre', truncating='pre', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yclMzflX5ayI"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "lb = LabelEncoder()\n",
    "train_label = lb.fit_transform(df_train['class'].values)\n",
    "train_label = to_categorical(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6lciZyr8jm9"
   },
   "source": [
    "## 词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szqA37Qm8l7B"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "wHL8iZsC8w1L",
    "outputId": "ad3d6941-2c4a-48e7-ab7a-988da3fd1a38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "embedding_matrix = np.zeros((len(vocab)+1, 200))\n",
    "for word, i in vocab.items():\n",
    "    embedding_vector = model.wv[word] if word in model else None\n",
    "    if embedding_vector is not None:\n",
    "        count += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        unknown_vec = np.random.random(200) * 0.5\n",
    "        unknown_vec = unknown_vec - unknown_vec.mean()\n",
    "        embedding_matrix[i] = unknown_vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJyYAQJmGIoc"
   },
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKJco6f4Cut1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Dense, BatchNormalization, Activation, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rseYnEINBv0q"
   },
   "outputs": [],
   "source": [
    "def build_model(sequence_length, embedding_weight, class_num):\n",
    "    content = Input(shape=(sequence_length, ), dtype='int32')\n",
    "    embedding = Embedding(\n",
    "        name='word_embedding',\n",
    "        input_dim=embedding_weight.shape[0],\n",
    "        weights=[embedding_weight],\n",
    "        output_dim=embedding_weight.shape[1],\n",
    "        trainable=False\n",
    "    )\n",
    "    x = SpatialDropout1D(0.2)(embedding(content))\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    x = Dense(1000)(conc)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(500)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    output = Dense(19, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=content, outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_ZNKaNzr3_B"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qRGXJcUlZjeX",
    "outputId": "cf45cdb9-ddd5-4a1e-bbe5-5c188e6f60b7"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "train_pre_matrix = np.zeros((df_train.shape[0], 19))\n",
    "test_pre_matrix = np.zeros((10, df_test.shape[0], 19))\n",
    "cv_scores = []\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(train_)):\n",
    "    x_train, x_valid = train_[train_index, :], train_[valid_index, :]\n",
    "    y_train, y_valid = train_label[train_index], train_label[valid_index]\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(64)\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(64)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_, np.zeros((test_.shape[0], 19)))).batch(64)\n",
    "    \n",
    "    model = build_model(1800, embedding_matrix, 19)\n",
    "    model.fit(train_ds, epochs=30, validation_data=valid_ds, verbose=1)\n",
    "    \n",
    "    valid_prob = model.predict(valid_ds)\n",
    "    valid_pred = np.argmax(valid_prob, axis=1)\n",
    "    valid_pred = lb.inverse_transform(valid_pred)\n",
    "    y_valid = np.argmax(y_valid, axis=1)\n",
    "    y_valid = lb.inverse_transform(y_valid)\n",
    "    f1_score = f1_score(y_valid, valid_pred, average='macro')\n",
    "    print(\"F1 score\", f1_score)\n",
    "    train_pre_matrix[valid_index, :] = valid_prob\n",
    "    test_pre_matrix[i, :, :] = model.predict(test_ds)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "np.save('test.npy', test_pre_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKlosTK5GLOy"
   },
   "source": [
    "## 结果融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BDij0kqugce"
   },
   "outputs": [],
   "source": [
    "res = np.load('test.npy')\n",
    "res_mean = np.mean(res, axis=0)\n",
    "test_pred = lb.inverse_transform(np.argmax(res_maean, axis=1))\n",
    "df_test['class'] = test_pred\n",
    "df_test[['id', 'class']].to_csv('submission.csv', index=False, header=True, encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "达观-文本分类.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
